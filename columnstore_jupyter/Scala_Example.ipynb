{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scala Example\n",
    "## Insert through JDBC\n",
    "Variables to connect to MariaDB ColumnStore throuhg JDBC are set and a SparkContext is initiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.Properties\n",
    "import org.apache.spark.sql.SQLContext\n",
    "\n",
    "val url = \"jdbc:mysql://columnstore_host_nm:3306\"\n",
    "\n",
    "var connectionProperties = new Properties()\n",
    "connectionProperties.put(\"user\", \"jupiter_user\")\n",
    "connectionProperties.put(\"password\", \"jupiter_pass\")\n",
    "connectionProperties.put(\"driver\", \"org.mariadb.jdbc.Driver\")\n",
    "\n",
    "val sqlContext = new SQLContext(sc)\n",
    "import sqlContext.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample DataFrame is created, that shows numbers and their ASCII representation,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val sampleDF = sc.makeRDD(0 to 127).map(i => (i, i.toChar.toString)).toDF(\"number\", \"ASCII_representation\")\n",
    "sampleDF.printSchema()\n",
    "sampleDF.registerTempTable(\"df\")\n",
    "sqlContext.sql(\"SELECT number, ASCII_representation from df WHERE number > 64 LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and is inserted into MariaDB CoumnStore through JDBC in database \"test\" table \"scalaexample\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDF.write.mode(\"overwrite\").\n",
    "  option(\"numPartitions\", 1).\n",
    "  option(\"createTableOptions\", \"ENGINE=columnstore\").\n",
    "  option(\"createTableColumnTypes\", \"number INT, ASCII_representation CHAR(1)\").\n",
    "  jdbc(url, \"test.scalaexample\", connectionProperties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert through native ColumnStore API (bulk insert)\n",
    "Variables to connect to MariaDB ColumnStore through the native ColumnStore API are already set in /usr/local/mariadb/columnstore/etc/Columnstore.xml.\n",
    "\n",
    "The necessary library is loaded, the ColumnStoreDriver is instantiated, and table \"scalaexample\" in database \"test\" is set for the bulk insert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.mariadb.columnstore.api.ColumnStoreDriver\n",
    "\n",
    "val d = new ColumnStoreDriver();\n",
    "var b = d.createBulkInsert(\"test\", \"scalaexample\", 0, 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is inserted into ColumnStore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (row <- sampleDF.collect()){\n",
    "    b.setColumn(0, row.getInt(0))\n",
    "    b.setColumn(1, row.getString(1))\n",
    "    b.writeRow()\n",
    "}\n",
    "b.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a summary of the insert process is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val summary = b.getSummary()\n",
    "println(\"Execution time: \" + summary.getExecutionTime())\n",
    "println(\"Rows inserted: \" + summary.getRowsInsertedCount())\n",
    "println(\"Truncation count: \" + summary.getTruncationCount())\n",
    "println(\"Saturated count: \" + summary.getSaturatedCount())\n",
    "println(\"Invalid count: \" + summary.getInvalidCount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert through custom function and ColumnStore API (automatic type detection)\n",
    "Requires an existing table with a corresponding schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.mariadb.columnstore.api.{ColumnStoreDriver,ColumnStoreDecimal,columnstore_data_types_t}\n",
    "import org.apache.spark.sql.{Row,DataFrame}\n",
    "import java.math.BigInteger\n",
    "\n",
    "object ColumnStoreExporter {\n",
    "  def export( database: String, table: String, df: DataFrame ) : Unit = {\n",
    "    val rows = df.collect()\n",
    "    val driver = new ColumnStoreDriver()\n",
    "    val bulkInsert = driver.createBulkInsert(database, table, 0, 0)\n",
    "\n",
    "    // get the column count of table\n",
    "    val dbCatalog = driver.getSystemCatalog\n",
    "    val dbTable = dbCatalog.getTable(database, table)\n",
    "    val dbTableColumnCount = dbTable.getColumnCount\n",
    "\n",
    "    // insert row by row into table\n",
    "    try {\n",
    "      for (row <- rows){\n",
    "        for (columnId <- 0 until row.size){\n",
    "          if (columnId < dbTableColumnCount){\n",
    "            row.get(columnId) match {\n",
    "              case input:Boolean => if (input) bulkInsert.setColumn(columnId, 1)\n",
    "              else bulkInsert.setColumn(columnId, 0);\n",
    "              case input:Byte => bulkInsert.setColumn(columnId, input)\n",
    "              case input:java.sql.Date => bulkInsert.setColumn(columnId, input.toString)\n",
    "              case input:java.math.BigDecimal =>\n",
    "                val dbColumn = dbTable.getColumn(columnId)\n",
    "                if (dbColumn.getType.equals(columnstore_data_types_t.DATA_TYPE_DECIMAL) ||\n",
    "                  dbColumn.getType.equals(columnstore_data_types_t.DATA_TYPE_UDECIMAL) ||\n",
    "                  dbColumn.getType.equals(columnstore_data_types_t.DATA_TYPE_FLOAT) ||\n",
    "                  dbColumn.getType.equals(columnstore_data_types_t.DATA_TYPE_UFLOAT) ||\n",
    "                  dbColumn.getType.equals(columnstore_data_types_t.DATA_TYPE_DOUBLE) ||\n",
    "                  dbColumn.getType.equals(columnstore_data_types_t.DATA_TYPE_UDOUBLE)){\n",
    "                  \n",
    "                  bulkInsert.setColumn(columnId, new ColumnStoreDecimal(input.toPlainString))\n",
    "                }\n",
    "                else {\n",
    "                  bulkInsert.setColumn(columnId, input.toBigInteger)\n",
    "                }\n",
    "              case input:Double => bulkInsert.setColumn(columnId, input)\n",
    "              case input:Float => bulkInsert.setColumn(columnId, input)\n",
    "              case input:Integer => bulkInsert.setColumn(columnId, input)\n",
    "              case input:Long => bulkInsert.setColumn(columnId, input)\n",
    "              case input:Short => bulkInsert.setColumn(columnId, input)\n",
    "              case input:String => bulkInsert.setColumn(columnId, input)\n",
    "              case input:java.sql.Timestamp => bulkInsert.setColumn(columnId, input.toString)\n",
    "              case _ => throw new Exception(\"Parsing error, can't convert \" +  row.get(columnId).getClass + \".\")\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        bulkInsert.writeRow()\n",
    "      }\n",
    "      bulkInsert.commit()\n",
    "    }\n",
    "    catch {\n",
    "      case e: Exception => bulkInsert.rollback(); e.printStackTrace();\n",
    "    }\n",
    "    finally{ // print a short summary of the insertion process\n",
    "      val summary = bulkInsert.getSummary\n",
    "      println(\"Execution time: \" + summary.getExecutionTime)\n",
    "      println(\"Rows inserted: \" + summary.getRowsInsertedCount)\n",
    "      println(\"Truncation count: \" + summary.getTruncationCount)\n",
    "      println(\"Saturated count: \" + summary.getSaturatedCount)\n",
    "      println(\"Invalid count: \" + summary.getInvalidCount)\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnStoreExporter.export(\"test\",\"scalaexample\",sampleDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
